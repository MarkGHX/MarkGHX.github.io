## News

<!-- - **[Oct. 2024]** Our paper &ldquo;MultiVerse: Exposing Large Language Model Alignment Problems in Diverse Worlds.&rdquo; is accepted by **NeurIPS 2024 Workshop on Safe GenAI**. Congrats to Xiaolong!
- **[Oct. 2024]** Our paper &ldquo;SkewAct: Red Teaming Large Language Models via Activation-Skewed Adversarial Prompt Optimization.&rdquo; is accepted by **NeurIPS 2024 Workshop on Red Teaming GenAI**.
- **[Sep. 2024]** Our paper &ldquo;BiScope: AI-generated Text Detection by Checking Memorization of Preceding Tokens.&rdquo; is accepted by **NeurIPS 2024**.
- **[Sep. 2024]** Our paper &ldquo;BAIT: Large Language Model Backdoor Scanning by Inverting Attack Target.&rdquo; is accepted by **S&P 2025**. Congrats to Guangyu!
- **[Jul. 2024]** Our new preprint &ldquo;Poisoning with A Pill: Circumventing Detection in Federated Learning.&rdquo; has been released, introducing a generic and attack-agnostic augmentation approach to enhance the effectiveness and stealthiness of existing poisoning attacks in federated learning.
- **[Jul. 2024]** Our paper &ldquo;UNIT: Backdoor Mitigation via Automated Neural Distribution Tightening.&rdquo; is accepted by **ECCV 2024**. Congrats to Siyuan!
- **[Feb. 2024]** Our paper &ldquo;Siren<sup>+</sup>: Robust Federated Learning with Proactive Alarming and Differential Privacy.&rdquo; is accepted by **IEEE TDSC**. -->
<!-- - **[Aug. 2021]** Our paper &ldquo;Siren: Byzantine-robust Federated Learning via Proactive Alarming.&rdquo; is accepted by **SoCC 2021**. -->
<!-- - **[Aug. 2021]** Our paper &ldquo;SpaceDML: Enabling Distributed Machine Learning in Space Information Networks.&rdquo; is accepted by **IEEE Network**. -->

<ul>
<li><strong>[Oct. 2024]</strong>Our paper &ldquo;MultiVerse: Exposing Large Language Model Alignment Problems in Diverse Worlds.&rdquo; is accepted by <strong>NeurIPS 2024 Workshop on Safe GenAI</strong>. Congrats to Xiaolong!</li>
<li><strong>[Oct. 2024]</strong>Our paper &ldquo;SkewAct: Red Teaming Large Language Models via Activation-Skewed Adversarial Prompt Optimization.&rdquo; is accepted by <strong>NeurIPS 2024 Workshop on Red Teaming GenAI</strong>.</li>
<li><strong>[Sep. 2024]</strong>Our paper &ldquo;BiScope: AI-generated Text Detection by Checking Memorization of Preceding Tokens.&rdquo; is accepted by <strong>NeurIPS 2024</strong>.</li>
<li><strong>[Sep. 2024]</strong>Our paper &ldquo;BAIT: Large Language Model Backdoor Scanning by Inverting Attack Target.&rdquo; is accepted by <strong>S&P 2025</strong>. Congrats to Guangyu!</li>
<li><strong>[Jul. 2024]</strong>Our new preprint &ldquo;Poisoning with A Pill: Circumventing Detection in Federated Learning.&rdquo; has been released, introducing a generic and attack-agnostic augmentation approach to enhance the effectiveness and stealthiness of existing poisoning attacks in federated learning.</li>
<a href="javascript:toggle_vis('newsmore')">Show more</a>
<div id="newsmore" style="display:none"> 
  <li><strong>[Jul. 2024]</strong>Our paper &ldquo;UNIT: Backdoor Mitigation via Automated Neural Distribution Tightening.&rdquo; is accepted by <strong>ECCV 2024</strong>. Congrats to Siyuan!</li>
  <li><strong>[Feb. 2024]</strong>Our paper &ldquo;Our paper &ldquo;Siren<sup>+</sup>: Robust Federated Learning with Proactive Alarming and Differential Privacy.&rdquo; is accepted by <strong>IEEE TDSC</strong>.</li>
  <li><strong>[Aug. 2021]</strong>Our paper &ldquo;Siren: Byzantine-robust Federated Learning via Proactive Alarming.&rdquo; is accepted by <strong>SoCC 2021</strong>.</li>
  <li><strong>[Aug. 2021]</strong>Our paper &ldquo;SpaceDML: Enabling Distributed Machine Learning in Space Information Networks.&rdquo; is accepted by <strong>IEEE Network</strong>.</li>
</div>

</ul>