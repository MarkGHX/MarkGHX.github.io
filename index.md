---
layout: homepage
---
## About Me

I am currently a second-year Ph.D. student in Computer Science at Purdue University, advised by [Prof. Xiangyu Zhang](https://www.cs.purdue.edu/homes/xyzhang/). Before joining Purdue, I received both of my M.Eng. degree and B.Eng. degree in Computer Science from Shanghai Jiao Tong University (SJTU), where I was supervised by [Prof. Ruhui Ma](https://scholar.google.com/citations?user=PcrtqDsAAAAJ&hl=en) and [Prof. Tao Song](https://scholar.google.com/citations?user=tIjK-3QAAAAJ&hl=en). I also worked with [Prof. Yang Hua](https://scholar.google.com/citations?user=N0tFi8MAAAAJ&hl=en), and [Prof. Hao Wang](https://intellisys.haow.ca/haowang/).

My research interests center around AI Security and Ethics, especially for such topics in Federated Learning and Large Language Models.

<!-- ## Research Interests

- **Computer Vision:** image recognition, image generation, video captioning
- **Machine Learning:** meta-learning, incremental learning, transfer learning -->

<br>
## News

- **[Oct. 2024]** Our paper &ldquo;MultiVerse: Exposing Large Language Model Alignment Problems in Diverse Worlds.&rdquo; is accepted by **NeurIPS 2024 Workshop on Safe GenAI**. Congrats to Xiaolong!
- **[Oct. 2024]** Our paper &ldquo;SkewAct: Red Teaming Large Language Models via Activation-Skewed Adversarial Prompt Optimization.&rdquo; is accepted by **NeurIPS 2024 Workshop on Red Teaming GenAI**.
- **[Sep. 2024]** Our paper &ldquo;BiScope: AI-generated Text Detection by Checking Memorization of Preceding Tokens.&rdquo; is accepted by **NeurIPS 2024**.
- **[Sep. 2024]** Our paper &ldquo;BAIT: Large Language Model Backdoor Scanning by Inverting Attack Target.&rdquo; is accepted by **S&P 2025**. Congrats to Guangyu!
- **[Jul. 2024]** Our new preprint &ldquo;Poisoning with A Pill: Circumventing Detection in Federated Learning.&rdquo; has been released, introducing a generic and attack-agnostic augmentation approach to enhance the effectiveness and stealthiness of existing poisoning attacks in federated learning.
- **[Jul. 2024]** Our paper &ldquo;UNIT: Backdoor Mitigation via Automated Neural Distribution Tightening.&rdquo; is accepted by **ECCV 2024**. Congrats to Siyuan!
- **[Feb. 2024]** Our paper &ldquo;Siren<sup>+</sup>: Robust Federated Learning with Proactive Alarming and Differential Privacy.&rdquo; is accepted by **IEEE TDSC**.
<!-- - **[Aug. 2021]** Our paper &ldquo;Siren: Byzantine-robust Federated Learning via Proactive Alarming.&rdquo; is accepted by **SoCC 2021**. -->
<!-- - **[Aug. 2021]** Our paper &ldquo;SpaceDML: Enabling Distributed Machine Learning in Space Information Networks.&rdquo; is accepted by **IEEE Network**. -->

<br>
{% include_relative _includes/publications.md %}

{% include_relative _includes/education.md %}
<br>

{% include_relative _includes/work.md %}
<br>

{% include_relative _includes/talks.md %}
<br>

{% include_relative _includes/awards.md %}
<br>

{% include_relative _includes/services.md %}
